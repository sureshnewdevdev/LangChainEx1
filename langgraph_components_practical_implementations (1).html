<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>LangGraph Components &amp; Practical Implementations – Notes</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
    body {
        margin: 0;
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        background-color: #f7f7fb;
        color: #222;
    }
    .page-header {
        background: linear-gradient(90deg, #8e24aa, #d81b60);
        color: #fff;
        padding: 18px 24px;
        box-shadow: 0 2px 6px rgba(0,0,0,0.2);
    }
    .page-header h1 {
        margin: 0;
        font-size: 1.6rem;
    }
    .page-header p {
        margin: 4px 0 0 0;
        font-size: 0.9rem;
        opacity: 0.9;
    }
    .layout {
        display: flex;
        min-height: calc(100vh - 70px);
    }
    .sidebar {
        width: 280px;
        background-color: #fff;
        border-right: 1px solid #e0e0e0;
        padding: 12px;
        box-sizing: border-box;
        position: sticky;
        top: 0;
        align-self: flex-start;
    }
    .sidebar-title {
        font-weight: 600;
        margin-bottom: 8px;
        font-size: 0.95rem;
        color: #8e24aa;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }
    .nav-link {
        display: block;
        margin-bottom: 6px;
        text-decoration: none;
        color: #fff;
        background-color: #a0007f;
        border-radius: 4px;
        padding: 8px 10px;
        font-size: 0.85rem;
        border: 1px solid #880e4f;
        box-shadow: 0 1px 2px rgba(0,0,0,0.15);
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }
    .nav-link:hover {
        background-color: #ba2d92;
    }
    .nav-section-separator {
        margin: 10px 0 4px 0;
        font-size: 0.8rem;
        font-weight: 600;
        color: #8e24aa;
        padding: 4px 6px;
        border-radius: 3px;
        background-color: #f3e5f5;
        border: 1px solid #e1bee7;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }
    .content {
        flex: 1;
        padding: 24px;
        box-sizing: border-box;
        max-width: 980px;
    }
    h2 {
        color: #8e24aa;
        border-bottom: 2px solid #f1e1f6;
        padding-bottom: 4px;
        margin-top: 28px;
    }
    h3 {
        color: #d81b60;
        margin-top: 20px;
    }
    p {
        line-height: 1.6;
        font-size: 0.95rem;
    }
    ul, ol {
        margin-left: 22px;
        font-size: 0.95rem;
    }
    .note-box {
        border-left: 4px solid #ffb300;
        background-color: #fff8e1;
        padding: 8px 12px;
        margin: 12px 0;
        font-size: 0.9rem;
    }
    .code-block {
        background-color: #263238;
        color: #eceff1;
        padding: 12px 14px;
        border-radius: 4px;
        font-family: "Consolas", "Courier New", monospace;
        font-size: 0.85rem;
        overflow-x: auto;
        margin: 10px 0 16px 0;
        white-space: pre;
    }
    .diagram {
        background-color: #fff;
        border: 1px dashed #bdbdbd;
        padding: 10px 12px;
        border-radius: 4px;
        font-family: "Consolas", "Courier New", monospace;
        font-size: 0.85rem;
        white-space: pre;
        overflow-x: auto;
        margin: 10px 0 16px 0;
    }
    .tag-pill {
        display: inline-block;
        background-color: #f3e5f5;
        color: #6a1b9a;
        border-radius: 999px;
        padding: 2px 10px;
        font-size: 0.75rem;
        margin-right: 4px;
        margin-bottom: 4px;
    }
    .section-meta {
        margin: 6px 0 10px 0;
    }
    @media (max-width: 900px) {
        .layout {
            flex-direction: column;
        }
        .sidebar {
            width: 100%;
            position: static;
            border-right: none;
            border-bottom: 1px solid #e0e0e0;
            display: flex;
            overflow-x: auto;
        }
        .sidebar-title {
            display: none;
        }
        .nav-section-separator {
            display: none;
        }
        .nav-link {
            flex: 0 0 auto;
            margin-right: 8px;
            margin-bottom: 0;
        }
        .content {
            padding: 16px;
        }
    }
</style>
</head>
<body>
<div class="page-header">
  <h1>LangGraph Components &amp; Practical Implementations</h1>
  <p>Detailed notes for building graph-based LLM workflows with LangGraph.</p>
</div>

<div class="layout">
  <nav class="sidebar">
    <div class="sidebar-title">LangGraph Components</div>
    <a class="nav-link" href="#state-pydantic">Defining State with Pydantic or TypedDict</a>
    <a class="nav-link" href="#nodes-functions">Building Nodes as Functions or Runnables</a>
    <a class="nav-link" href="#conditional-static-edges">Adding Conditional and Static Edges</a>
    <a class="nav-link" href="#end-keywords">Using &quot;END&quot; and Special Keywords</a>
    <a class="nav-link" href="#tools-llms-graphs">Integrating Tools and LLMs into Graphs</a>

    <div class="nav-section-separator">Practical Implementations</div>
    <a class="nav-link" href="#multi-agent-workflows">Building Multi-Agent Workflows</a>
    <a class="nav-link" href="#human-in-the-loop">Creating Human-in-the-Loop Systems</a>
    <a class="nav-link" href="#error-handling-retry">Error Handling and Retry Logic in Graphs</a>
    <a class="nav-link" href="#debug-visualize">Debugging and Visualizing Graph Execution</a>
  </nav>

  <main class="content">

    <section id="state-pydantic">
      <h2>1. Defining State with Pydantic or TypedDict</h2>
      <div class="section-meta">
        <span class="tag-pill">LangGraph Components</span>
        <span class="tag-pill">State</span>
      </div>

      <h3>1.1 What is &quot;State&quot; in LangGraph?</h3>
      <p>
        In LangGraph, the <strong>state</strong> is the data that flows through your graph.
        Each node reads from the state and writes back to it. Defining the state clearly
        ensures:
      </p>
      <ul>
        <li>Type safety (you know which keys exist and what their types are).</li>
        <li>Clear contracts between nodes.</li>
        <li>Easier debugging and validation.</li>
      </ul>

      <div class="diagram">
State example
-------------

{
  "user_input": "Explain RAG with a Databricks example.",
  "plan": "...",
  "documents": [...],
  "answer": "..."
}
      </div>

      <h3>1.2 State with TypedDict (lightweight)</h3>
      <p>
        For quick demos, you can use <code>TypedDict</code> from the <code>typing</code> module:
      </p>

      <div class="code-block">
from typing import TypedDict, List, Optional

class GraphState(TypedDict, total=False):
    user_input: str
    plan: str
    documents: List[str]
    answer: str
      </div>

      <p>
        Here <code>total=False</code> means keys are optional. Each node can read or write
        only the keys it needs.
      </p>

      <h3>1.3 State with Pydantic (richer validation)</h3>
      <p>
        For production-grade apps you usually prefer <strong>Pydantic models</strong>.
      </p>

      <div class="code-block">
from typing import List, Optional
from pydantic import BaseModel, Field

class GraphState(BaseModel):
    user_input: str = Field(..., description="Latest user query")
    plan: Optional[str] = Field(None, description="High-level plan from planner")
    documents: List[str] = Field(default_factory=list, description="Retrieved docs")
    answer: Optional[str] = None
      </div>

      <div class="note-box">
        <strong>Tip:</strong> For teaching, start with <code>TypedDict</code> (simpler syntax),
        then show how Pydantic adds validation and helpful error messages.
      </div>
    </section>

    <section id="nodes-functions">
      <h2>2. Building Nodes as Functions or Runnables</h2>
      <div class="section-meta">
        <span class="tag-pill">Nodes</span>
        <span class="tag-pill">Execution Units</span>
      </div>

      <h3>2.1 What is a Node?</h3>
      <p>
        A <strong>node</strong> is a step in the graph. It receives the current state,
        performs some work, and returns an updated state. Examples:
      </p>
      <ul>
        <li>Planner node – decides what to do next.</li>
        <li>Retriever node – fetches relevant docs.</li>
        <li>Answer node – calls LLM to generate final answer.</li>
      </ul>

      <h3>2.2 Node as a Simple Function</h3>
      <div class="code-block">
from typing import Dict

def plan_node(state: Dict) -> Dict:
    user_input = state["user_input"]
    plan = f"Answer the question about: {user_input}"
    state["plan"] = plan
    return state
      </div>

      <p>
        Functions are the simplest form of nodes. LangGraph will call them whenever
        execution reaches that node.
      </p>

      <h3>2.3 Node as a Runnable (LLM-based)</h3>
      <p>
        For LLM calls, we usually use <strong>Runnables</strong> (LCEL components).
      </p>

      <div class="code-block">
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

answer_prompt = ChatPromptTemplate.from_template(
    "Use the documents below to answer the question.\n"
    "Question: {user_input}\n"
    "Documents: {documents}"
)

answer_chain = answer_prompt | llm | StrOutputParser()

def answer_node(state: Dict) -> Dict:
    answer = answer_chain.invoke(
        {"user_input": state["user_input"], "documents": state.get("documents", [])}
    )
    state["answer"] = answer
    return state
      </div>

      <p>
        Each node encapsulates one clear responsibility. This makes your LangGraph
        workflows modular and easier to reuse.
      </p>
    </section>

    <section id="conditional-static-edges">
      <h2>3. Adding Conditional and Static Edges</h2>
      <div class="section-meta">
        <span class="tag-pill">Edges</span>
        <span class="tag-pill">Control Flow</span>
      </div>

      <h3>3.1 Static Edges</h3>
      <p>
        A <strong>static edge</strong> always goes from one node to the next.
        Example: <code>start → plan → retrieve → answer → END</code>.
      </p>

      <div class="diagram">
[start] ──► [plan] ──► [retrieve] ──► [answer] ──► [END]
      </div>

      <h3>3.2 Conditional Edges</h3>
      <p>
        Conditional edges decide the next node based on state. For example:
      </p>
      <ul>
        <li>If no documents were found, go to a <code>fallback</code> node.</li>
        <li>If the question is &quot;planning&quot;, re-route to a different sub-graph.</li>
      </ul>

      <div class="code-block">
from langgraph.graph import StateGraph, END

def route_after_retrieve(state: Dict) -> str:
    if not state.get("documents"):
        return "fallback"
    return "answer"

workflow = StateGraph(dict)

workflow.add_node("plan", plan_node)
workflow.add_node("retrieve", lambda s: s)  # placeholder
workflow.add_node("answer", answer_node)
workflow.add_node("fallback", lambda s: {**s, "answer": "No docs found."})

workflow.set_entry_point("plan")
workflow.add_edge("plan", "retrieve")

# conditional edge from "retrieve"
workflow.add_conditional_edges(
    "retrieve",
    route_after_retrieve,
    {
        "answer": "answer",
        "fallback": "fallback",
    },
)

workflow.add_edge("answer", END)
workflow.add_edge("fallback", END)
      </div>

      <p>
        Here <code>route_after_retrieve</code> inspects the state and returns a label,
        which is mapped to the next node.
      </p>
    </section>

    <section id="end-keywords">
      <h2>4. Using &quot;END&quot; and Special Keywords</h2>
      <div class="section-meta">
        <span class="tag-pill">Graph Lifecycle</span>
      </div>

      <h3>4.1 END Node</h3>
      <p>
        <code>END</code> is a special constant imported from <code>langgraph.graph</code>
        that marks where graph execution stops.
      </p>
      <div class="code-block">
from langgraph.graph import END

workflow.add_edge("answer", END)
      </div>

      <p>
        You can have multiple paths that reach <code>END</code> (success, error, fallback, etc.).
      </p>

      <h3>4.2 START / Entry Point</h3>
      <p>
        Instead of a dedicated <code>START</code> node, LangGraph uses
        <code>set_entry_point("node_name")</code> to define which node receives
        the initial state.
      </p>

      <div class="code-block">
workflow.set_entry_point("plan")
      </div>

      <h3>4.3 Other Special Concepts</h3>
      <ul>
        <li><strong>Checkpoints</strong> (depending on version) – saving state mid-graph for resuming.</li>
        <li><strong>Subgraphs</strong> – graphs composed as single nodes inside a larger graph.</li>
      </ul>
    </section>

    <section id="tools-llms-graphs">
      <h2>5. Integrating Tools and LLMs into Graphs</h2>
      <div class="section-meta">
        <span class="tag-pill">Tools</span>
        <span class="tag-pill">LLMs</span>
      </div>

      <h3>5.1 Typical Pattern</h3>
      <p>
        The most common pattern for a LangGraph node is:
      </p>
      <ol>
        <li>Read fields from state.</li>
        <li>Call an LLM chain or a tool function.</li>
        <li>Write the result back into the state.</li>
      </ol>

      <h3>5.2 Example: Tool Node in the Graph</h3>
      <div class="code-block">
from langchain.tools import tool

@tool
def get_exchange_rate(currency: str) -> str:
    "Get the INR exchange rate for a given currency (dummy implementation)."
    rates = {"USD": "83.2", "EUR": "90.1"}
    return rates.get(currency.upper(), "Rate not available.")

def rate_node(state: Dict) -> Dict:
    result = get_exchange_rate.invoke({"currency": "USD"})
    state["rate_info"] = result
    return state
      </div>

      <p>
        This node can be inserted anywhere in the graph where you need live data.
      </p>

      <h3>5.3 Example: LLM Tool-Calling Inside a Node</h3>
      <p>
        You can also use an <strong>agent-like</strong> chain inside a node.
      </p>

      <div class="code-block">
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_openai import ChatOpenAI

tools = [get_exchange_rate]
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

agent_prompt = create_tool_calling_agent.create_prompt(tools)
agent = create_tool_calling_agent(llm, tools, agent_prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

def finance_helper_node(state: Dict) -> Dict:
    question = state["user_input"]
    result = agent_executor.invoke({"input": question})
    state["finance_answer"] = result["output"]
    return state
      </div>
    </section>

    <section id="multi-agent-workflows">
      <h2>6. Building Multi-Agent Workflows</h2>
      <div class="section-meta">
        <span class="tag-pill">Practical</span>
        <span class="tag-pill">Multi-agent</span>
      </div>

      <h3>6.1 Why Use LangGraph for Multi-Agent?</h3>
      <p>
        Multi-agent systems involve multiple LLM-powered roles coordinating:
      </p>
      <ul>
        <li>Planner agent</li>
        <li>Tool specialist agent</li>
        <li>Reviewer or critic agent</li>
      </ul>
      <p>
        LangGraph is ideal because each agent can be a node or subgraph and
        the edges describe how they interact.
      </p>

      <h3>6.2 Example Layout</h3>
      <div class="diagram">
[user_input] 
   │
   ▼
[planner_node] ──► [research_agent_node] ──► [writer_agent_node] ──► [reviewer_agent_node] ──► END
      </div>

      <p>
        Each node may internally be an agent with its own tools and memory, but
        the overall coordination is transparent in the graph.
      </p>
    </section>

    <section id="human-in-the-loop">
      <h2>7. Creating Human-in-the-Loop Systems</h2>
      <div class="section-meta">
        <span class="tag-pill">HITL</span>
        <span class="tag-pill">Approval</span>
      </div>

      <h3>7.1 Where Does the Human Fit?</h3>
      <p>
        Common checkpoints where humans intervene:
      </p>
      <ul>
        <li>Approving a plan or workflow.</li>
        <li>Editing a generated answer before sending to end user.</li>
        <li>Labeling outputs for future fine-tuning.</li>
      </ul>

      <h3>7.2 HITL Node Concept</h3>
      <p>
        For a teaching-friendly mental model, imagine a &quot;pause&quot; node:
      </p>
      <div class="diagram">
... ──► [draft_answer_node] ──► [human_review_node] ──► [final_send_node]
      </div>

      <p>
        The <code>human_review_node</code> could:
      </p>
      <ul>
        <li>Write the draft to a database or queue.</li>
        <li>Wait for a human to edit/approve.</li>
        <li>Resume the graph once approval is stored.</li>
      </ul>

      <div class="note-box">
        <strong>Implementation hint:</strong> Practically this often involves an
        external workflow system plus a status flag in the state to indicate
        &quot;waiting for human&quot; vs &quot;approved&quot;.
      </div>
    </section>

    <section id="error-handling-retry">
      <h2>8. Error Handling and Retry Logic in Graphs</h2>
      <div class="section-meta">
        <span class="tag-pill">Reliability</span>
        <span class="tag-pill">Resilience</span>
      </div>

      <h3>8.1 Why Handle Errors at Graph Level?</h3>
      <p>
        LLM + tool workflows can fail at many points:
      </p>
      <ul>
        <li>Rate limits or timeouts from external APIs.</li>
        <li>Parsing errors for tool outputs.</li>
        <li>Unexpected state shapes.</li>
      </ul>

      <h3>8.2 Retry Wrapper for a Node</h3>
      <p>
        A simple pattern is to wrap the node logic with retry logic.
      </p>

      <div class="code-block">
import time
from typing import Callable

def with_retry(node_fn: Callable, retries: int = 3, delay: float = 1.0):
    def wrapper(state: Dict) -> Dict:
        last_exc = None
        for _ in range(retries):
            try:
                return node_fn(state)
            except Exception as e:
                last_exc = e
                time.sleep(delay)
        # if all retries fail, add error info to state
        state["error"] = str(last_exc)
        return state
    return wrapper

safe_answer_node = with_retry(answer_node, retries=2, delay=0.5)
      </div>

      <p>
        In the graph you can send states that contain <code>error</code> to a dedicated
        <code>error_handler</code> node to log or alert.
      </p>
    </section>

    <section id="debug-visualize">
      <h2>9. Debugging and Visualizing Graph Execution</h2>
      <div class="section-meta">
        <span class="tag-pill">Debugging</span>
        <span class="tag-pill">Visualization</span>
      </div>

      <h3>9.1 Visualizing the Graph Structure</h3>
      <p>
        A simple teaching approach is to draw the graph explicitly:
      </p>

      <div class="diagram">
Nodes:
  plan, retrieve, answer, fallback, END

Edges:
  plan -> retrieve
  retrieve -> answer (if docs found)
  retrieve -> fallback (if no docs)
  answer -> END
  fallback -> END
      </div>

      <h3>9.2 Logging State at Each Node</h3>
      <p>
        During development you can add print/log statements inside nodes:
      </p>

      <div class="code-block">
def debug_node(name: str):
    def _inner(state: Dict) -> Dict:
        print(f"[DEBUG] at {name}, state keys:", list(state.keys()))
        return state
    return _inner

workflow.add_node("debug_after_plan", debug_node("debug_after_plan"))
workflow.add_edge("plan", "debug_after_plan")
workflow.add_edge("debug_after_plan", "retrieve")
      </div>

      <h3>9.3 Combining with LangSmith</h3>
      <p>
        Tracing the graph runs with LangSmith gives a detailed tree:
      </p>
      <ul>
        <li>Each node call = one span.</li>
        <li>Inside each span you see prompts, LLM responses, and tool calls.</li>
        <li>You can replay runs or compare different versions of the graph.</li>
      </ul>
    </section>

  </main>
</div>
</body>
</html>
